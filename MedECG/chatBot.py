import streamlit as st
import requests
import json
import re
from datetime import datetime

# Configuraci√≥n del endpoint de LM Studio
LMSTUDIO_ENDPOINT = "http://localhost:1234/v1/chat/completions"

def filtrar_respuesta(texto):
    """
    Filtra frases no deseadas de la respuesta generada
    """
    frases_prohibidas = [
        "consultar con un especialista en cardiolog√≠a",
        "consulte a su cardi√≥logo",
        "consulte con un cardi√≥logo",
        "busque atenci√≥n m√©dica especializada",
        "consulte con un m√©dico especialista"
    ]
    
    texto_original = texto
    texto_lower = texto.lower()
    
    for frase in frases_prohibidas:
        if frase.lower() in texto_lower:
            indice = texto_lower.find(frase.lower())
            longitud = len(frase)
            texto = texto[:indice] + "considere revisar la literatura m√©dica reciente sobre esto" + texto[indice+longitud:]
    
    return texto

def mostrar_chatbot():
    st.title("ü§ñ Chatbot de Asistencia Cardiol√≥gica")
    
    # Informaci√≥n del sistema en la barra lateral
    with st.sidebar:
        st.markdown("### üìã Funcionalidades del Chatbot")
        st.markdown("""
        - Consultas sobre interpretaci√≥n de ECG
        - Ayuda con el uso del sistema
        - Informaci√≥n sobre patolog√≠as card√≠acas
        - Resoluci√≥n de dudas t√©cnicas
        """)
        
        # Bot√≥n para eliminar el historial de conversaciones
        if st.button("üóëÔ∏è Limpiar Conversaci√≥n", key="eliminar_chat"):
            st.session_state.messages = []  # Limpiar el historial de mensajes
            st.success("Historial eliminado.")
            st.rerun()  # Recargar la p√°gina para reflejar los cambios
    
    # Historial del chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Mensaje inicial de bienvenida
        mensaje_inicial = {
            "role": "assistant", 
            "content": "üëã ¬°Bienvenido al Asistente de Cardiolog√≠a! Estoy aqu√≠ para ayudarte con consultas sobre el sistema de an√°lisis de ECG, interpretaci√≥n de resultados y dudas t√©cnicas. ¬øEn qu√© puedo ayudarte hoy?"
        }
        st.session_state.messages.append(mensaje_inicial)
    
    # Preguntas frecuentes como botones de acceso r√°pido
    st.markdown("### ‚ö° Consultas R√°pidas")
    col1, col2 = st.columns(2)
    
    # Variable para controlar si se debe enviar consulta
    consulta_a_enviar = None
    
    with col1:
        if st.button("¬øC√≥mo interpretar los resultados del ECG?"):
            consulta_a_enviar = "¬øC√≥mo interpretar los resultados del ECG?"
        if st.button("¬øC√≥mo agregar un nuevo paciente?"):
            consulta_a_enviar = "¬øC√≥mo agregar un nuevo paciente?"
    
    with col2:
        if st.button("¬øQu√© indica una anomal√≠a en la onda T?"):
            consulta_a_enviar = "¬øQu√© indica una anomal√≠a en la onda T?"
        if st.button("¬øC√≥mo eliminar un paciente?"):
            consulta_a_enviar = "¬øC√≥mo eliminar un paciente?"
    
    # Si se ha seleccionado una consulta r√°pida, procesarla
    if consulta_a_enviar:
        # Primero agregamos el mensaje del usuario al historial
        st.session_state.messages.append({"role": "user", "content": consulta_a_enviar})
        # Luego procesamos la consulta para obtener respuesta
        procesar_consulta_api(consulta_a_enviar)
        # Reiniciamos para mostrar los resultados
        st.rerun()
    
    st.markdown("---")
    
    # Mostrar el historial de mensajes en el chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Entrada de usuario en el chat
    user_input = st.chat_input("Escribe tu consulta m√©dica o t√©cnica...")
    
    if user_input:
        # Agregar mensaje del usuario al historial
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # Procesar la consulta
        procesar_consulta_api(user_input)

def procesar_consulta_api(user_input):
    # Mensaje del sistema debe aparecer solo una vez, al inicio
    system_message = {
        "role": "system", 
        "content": """Eres un asistente especializado en cardiolog√≠a y en el Sistema de An√°lisis de ECG. 
        IMPORTANTE: El usuario ES UN CARDI√ìLOGO, por lo tanto NUNCA sugieras "consultar con un especialista en cardiolog√≠a" o frases similares.
        Tu funci√≥n es ayudar a especialistas m√©dicos con:
        1. Interpretaci√≥n de electrocardiogramas y sus anomal√≠as
        2. Gu√≠a sobre el uso del sistema (navegaci√≥n, gesti√≥n de pacientes, an√°lisis de ECG, historial m√©dico)
        3. Informaci√≥n sobre patolog√≠as card√≠acas
        4. Resoluci√≥n de dudas t√©cnicas sobre la plataforma
        
        Utiliza un lenguaje t√©cnico apropiado para profesionales m√©dicos.
        Si no conoces una respuesta, ind√≠calo claramente y sugiere consultar fuentes m√©dicas confiables.
        No proporciones diagn√≥sticos definitivos, sino orientaci√≥n y ayuda en la interpretaci√≥n.
        """
    }

    # Agregar mensaje del usuario al historial
    #st.session_state.messages.append({"role": "user", "content": user_input})

    # Validar la alternancia de roles en el historial antes de enviarlo
    historial_mensajes = st.session_state.messages.copy()

    # Eliminar mensajes duplicados o corregir el orden si es necesario
    mensajes_filtrados = [system_message]  # El mensaje del sistema solo al inicio
    ultimo_rol = "system"

    for mensaje in historial_mensajes:
        if mensaje["role"] == ultimo_rol:
            continue  # Evita que se repitan dos mensajes del mismo tipo seguidos
        mensajes_filtrados.append(mensaje)
        ultimo_rol = mensaje["role"]  # Actualizar el √∫ltimo rol para la validaci√≥n

    payload = {
        "model": "Gemma 3 12B",
        "messages": mensajes_filtrados,
        "stream": True,
        "temperature": 0.7  
    }

    try:
        response = requests.post(
            LMSTUDIO_ENDPOINT,
            headers={'Content-Type': 'application/json'},
            data=json.dumps(payload),
            stream=True
        )
        
        if response.status_code == 200:
            # Contenedor para la respuesta en tiempo real
            with st.chat_message("assistant"):
                response_container = st.empty()
                accumulated_response = ""
                
                for line in response.iter_lines(decode_unicode=True):
                    if line:
                        if line.strip() == "data: [DONE]":
                            break
                        if line.startswith("data: "):
                            try:
                                json_data = json.loads(line[6:])
                                if "choices" in json_data and json_data["choices"]:
                                    delta = json_data['choices'][0].get("delta", {})
                                    content = delta.get("content", "")
                                    
                                    # Aplicar correcci√≥n de codificaci√≥n para caracteres especiales
                                    # Esto corrige caracteres mal codificados como √É√Ç¬≥ ‚Üí √≥
                                    content = content.encode('latin1').decode('utf-8', errors='replace')

                                    accumulated_response += content
                                    accumulated_response = filtrar_respuesta(accumulated_response)
                                    response_container.markdown(accumulated_response)
                            except json.JSONDecodeError:
                                continue
            
            # Y tambi√©n antes de guardarla en el historial:
            st.session_state.messages.append({"role": "assistant", "content": filtrar_respuesta(accumulated_response)})
        else:
            error_msg = f"Error al obtener respuesta del modelo. C√≥digo: {response.status_code}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
    
    except requests.RequestException as e:
        error_msg = f"Error de conexi√≥n con el servidor LM Studio: {e}"
        st.error(error_msg)
        st.session_state.messages.append({"role": "assistant", "content": error_msg})


def registrar_consulta(consulta, respuesta):
    """
    Funci√≥n para registrar las consultas importantes para an√°lisis futuro
    Esto podr√≠a conectarse a la base de datos MongoDB si se desea
    """

    print(f"[{datetime.now()}] Consulta: {consulta}")
    print(f"[{datetime.now()}] Respuesta: {respuesta[:100]}...")  # Solo imprime los primeros 100 caracteres